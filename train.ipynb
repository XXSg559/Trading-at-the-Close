{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_and_process_data, create_stock_dataset\n",
    "from model import Decoder, combined_rotary_embedding, custom_mask, causal_mask\n",
    "from bit.bitlinear import replace_with_bitnet_linear\n",
    "from bit.RMSNorm import RMSNorm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_days = 29\n",
    "days = 30\n",
    "# 超参数\n",
    "lr = 1e-4\n",
    "steps = 1\n",
    "batch_size = 8\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_and_process_data()\n",
    "stock_dataset = create_stock_dataset(data,seq_length=days)\n",
    "train_loader = DataLoader(stock_dataset, batch_size=batch_size, shuffle=False,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1650, 12])\n"
     ]
    }
   ],
   "source": [
    "# 输出loader的数据\n",
    "for i in train_loader:\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7155"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"d_model\": 128,\n",
    "    \"n_head\": 4,\n",
    "    \"dim_feedforward\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "}\n",
    "# torch模型 list\n",
    "# @torch.compile\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self,d_model,n_head,dim_feedforward,num_layers,dropout):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(12, d_model)\n",
    "        self.norm = RMSNorm(d_model)\n",
    "        self.decoder = Decoder(**args)\n",
    "        self.lm_head = nn.Linear(d_model,1)\n",
    "\n",
    "    def forward(self, x, positions_ids,mask):\n",
    "        x = self.fc1(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.decoder(x,positions_ids,mask)\n",
    "        x = x[:, -1, :]\n",
    "        x = self.lm_head(x)\n",
    "        return x\n",
    "model = MyModel(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功替换了所有 nn.Linear 层为 BitLinear 层。\n"
     ]
    }
   ],
   "source": [
    "model = replace_with_bitnet_linear(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal = causal_mask(days*55)\n",
    "pos = custom_mask(days*55,12,past_days,55)\n",
    "positions_ids = combined_rotary_embedding(30, 55, args['d_model']*2//args['n_head'],500,20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal , pos ,positions_ids = causal.to(device=device) , pos.to(device=device) ,tuple(i.to(device=device) for i in positions_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "\n",
    "device = accelerator.device\n",
    "model, optimizer, train_loader, = accelerator.prepare(\n",
    "    model, optimizer, train_loader, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda'), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.device, pos.device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step 1/1:   0%|          | 14/7155 [02:18<19:29:36,  9.83s/batch, loss=5.4365]"
     ]
    }
   ],
   "source": [
    "# 训练,用tqdm显示进度\n",
    "\n",
    "model.train()\n",
    "\n",
    "for step in range(steps):\n",
    "    total_loss = 0  # 累积损失\n",
    "    batch_count = 0  # 计算 batch 数量\n",
    "\n",
    "    with tqdm(train_loader, desc=f\"Step {step+1}/{steps}\", unit=\"batch\") as train_pbar:\n",
    "        for x in train_pbar:  # tqdm 追踪 train_loader\n",
    "            batch_loss = 0  # 追踪当前 batch 的损失\n",
    "            for i in range((days - past_days) * 55):\n",
    "                optimizer.zero_grad()\n",
    "                y = x[:, past_days * 55 + i, -1].unsqueeze(-1)  # 确保 y 形状匹配 y_pred\n",
    "                input = x * pos[i]  \n",
    "                y_pred = model(input, positions_ids, causal)  # 模型预测\n",
    "\n",
    "                loss = criterion(y_pred, y)  # 计算损失\n",
    "                loss.backward()  # 反向传播\n",
    "                optimizer.step()  # 更新参数\n",
    "\n",
    "                batch_loss += loss.item()  # 记录当前 batch 损失\n",
    "                total_loss += loss.item()  # 记录总损失\n",
    "                batch_count += 1  # 增加 batch 计数\n",
    "            \n",
    "            avg_batch_loss = batch_loss / ((days - past_days) * 55)  # 计算当前 batch 的平均损失\n",
    "            train_pbar.set_postfix(loss=f\"{avg_batch_loss:.4f}\")  # 在进度条旁边显示 batch 级别的损失\n",
    "\n",
    "    avg_loss = total_loss / batch_count if batch_count > 0 else 0\n",
    "    tqdm.write(f\"Step {step+1}/{steps}, Average Loss: {avg_loss:.4f}\")  # 每个 step 结束后打印平均损失\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
